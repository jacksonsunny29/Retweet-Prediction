{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb27b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source brt/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "170192b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26608631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "#tokenization\n",
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"#+ text + \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Print out the tokens.\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7981434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knight',\n",
       " 'lap',\n",
       " 'survey',\n",
       " 'ma',\n",
       " '##ow',\n",
       " 'noise',\n",
       " 'billy',\n",
       " '##ium',\n",
       " 'shooting',\n",
       " 'guide',\n",
       " 'bedroom',\n",
       " 'priest',\n",
       " 'resistance',\n",
       " 'motor',\n",
       " 'homes',\n",
       " 'sounded',\n",
       " 'giant',\n",
       " '##mer',\n",
       " '150',\n",
       " 'scenes',\n",
       " 'equal',\n",
       " 'comic',\n",
       " 'patients',\n",
       " 'hidden',\n",
       " 'solid',\n",
       " 'actual',\n",
       " 'bringing',\n",
       " 'afternoon',\n",
       " 'touched',\n",
       " 'funds',\n",
       " 'wedding',\n",
       " 'consisted',\n",
       " 'marie',\n",
       " 'canal',\n",
       " 'sr',\n",
       " 'kim',\n",
       " 'treaty',\n",
       " 'turkish',\n",
       " 'recognition',\n",
       " 'residence',\n",
       " 'cathedral',\n",
       " 'broad',\n",
       " 'knees',\n",
       " 'incident',\n",
       " 'shaped',\n",
       " 'fired',\n",
       " 'norwegian',\n",
       " 'handle',\n",
       " 'cheek',\n",
       " 'contest',\n",
       " 'represent',\n",
       " '##pe',\n",
       " 'representing',\n",
       " 'beauty',\n",
       " '##sen',\n",
       " 'birds',\n",
       " 'advantage',\n",
       " 'emergency',\n",
       " 'wrapped',\n",
       " 'drawing',\n",
       " 'notice',\n",
       " 'pink',\n",
       " 'broadcasting',\n",
       " '##ong',\n",
       " 'somehow',\n",
       " 'bachelor',\n",
       " 'seventh',\n",
       " 'collected',\n",
       " 'registered',\n",
       " 'establishment',\n",
       " 'alan',\n",
       " 'assumed',\n",
       " 'chemical',\n",
       " 'personnel',\n",
       " 'roger',\n",
       " 'retirement',\n",
       " 'jeff',\n",
       " 'portuguese',\n",
       " 'wore',\n",
       " 'tied',\n",
       " 'device',\n",
       " 'threat',\n",
       " 'progress',\n",
       " 'advance',\n",
       " '##ised',\n",
       " 'banks',\n",
       " 'hired',\n",
       " 'manchester',\n",
       " 'nfl',\n",
       " 'teachers',\n",
       " 'structures',\n",
       " 'forever',\n",
       " '##bo',\n",
       " 'tennis',\n",
       " 'helping',\n",
       " 'saturday',\n",
       " 'sale',\n",
       " 'applications',\n",
       " 'junction',\n",
       " 'hip',\n",
       " 'incorporated',\n",
       " 'neighborhood',\n",
       " 'dressed',\n",
       " 'ceremony',\n",
       " '##ds',\n",
       " 'influenced',\n",
       " 'hers',\n",
       " 'visual',\n",
       " 'stairs',\n",
       " 'decades',\n",
       " 'inner',\n",
       " 'kansas',\n",
       " 'hung',\n",
       " 'hoped',\n",
       " 'gain',\n",
       " 'scheduled',\n",
       " 'downtown',\n",
       " 'engaged',\n",
       " 'austria',\n",
       " 'clock',\n",
       " 'norway',\n",
       " 'certainly',\n",
       " 'pale',\n",
       " 'protected',\n",
       " '1913',\n",
       " 'victor',\n",
       " 'employees',\n",
       " 'plate',\n",
       " 'putting',\n",
       " 'surrounded',\n",
       " '##ists',\n",
       " 'finishing',\n",
       " 'blues',\n",
       " 'tropical',\n",
       " '##ries',\n",
       " 'minnesota',\n",
       " 'consider',\n",
       " 'philippines',\n",
       " 'accept',\n",
       " '54',\n",
       " 'retrieved',\n",
       " '1900',\n",
       " 'concern',\n",
       " 'anderson',\n",
       " 'properties',\n",
       " 'institution',\n",
       " 'gordon',\n",
       " 'successfully',\n",
       " 'vietnam',\n",
       " '##dy',\n",
       " 'backing',\n",
       " 'outstanding',\n",
       " 'muslim',\n",
       " 'crossing',\n",
       " 'folk',\n",
       " 'producing',\n",
       " 'usual',\n",
       " 'demand',\n",
       " 'occurs',\n",
       " 'observed',\n",
       " 'lawyer',\n",
       " 'educated',\n",
       " '##ana',\n",
       " 'kelly',\n",
       " 'string',\n",
       " 'pleasure',\n",
       " 'budget',\n",
       " 'items',\n",
       " 'quietly',\n",
       " 'colorado',\n",
       " 'philip',\n",
       " 'typical',\n",
       " '##worth',\n",
       " 'derived',\n",
       " '600',\n",
       " 'survived',\n",
       " 'asks',\n",
       " 'mental',\n",
       " '##ide',\n",
       " '56',\n",
       " 'jake',\n",
       " 'jews',\n",
       " 'distinguished',\n",
       " 'ltd',\n",
       " '1911',\n",
       " 'sri',\n",
       " 'extremely',\n",
       " '53',\n",
       " 'athletic',\n",
       " 'loud',\n",
       " 'thousands',\n",
       " 'worried',\n",
       " 'shadow',\n",
       " 'transportation',\n",
       " 'horses',\n",
       " 'weapon',\n",
       " 'arena',\n",
       " 'importance',\n",
       " 'users',\n",
       " 'tim',\n",
       " 'objects',\n",
       " 'contributed',\n",
       " 'dragon',\n",
       " 'douglas',\n",
       " 'aware',\n",
       " 'senator',\n",
       " 'johnny',\n",
       " 'jordan',\n",
       " 'sisters',\n",
       " 'engines',\n",
       " 'flag',\n",
       " 'investment',\n",
       " 'samuel',\n",
       " 'shock',\n",
       " 'capable',\n",
       " 'clark',\n",
       " 'row',\n",
       " 'wheel',\n",
       " 'refers',\n",
       " 'session']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.vocab.keys())[5000:5220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9a94902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "problem       3,291\n",
      "##e           2,063\n",
      "central       2,430\n",
      "fa            6,904\n",
      "##uss        17,854\n",
      "##e           2,063\n",
      "democrat      7,672\n",
      "##ie          2,666\n",
      "go            2,175\n",
      "##uve        22,909\n",
      "##rne        12,119\n",
      "##ment        3,672\n",
      "coalition     6,056\n",
      "proportion   10,817\n",
      "##nell        9,091\n",
      "##e           2,063\n",
      "ju           18,414\n",
      "##re          2,890\n",
      ".             1,012\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "text = \"problème central fausse démocratie gouvernement coalition proportionnelle juré.\"\n",
    "\n",
    "# Add the special tokens.\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a076e99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e6f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea0e1b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased',output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e43c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    # Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "# hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5233ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model = bert_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1e3972d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x7f9e365a28c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bruce/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1162, in __del__\n",
      "    self.close()\n",
      "  File \"/home/bruce/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 288, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "  File \"/home/bruce/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 160, in display\n",
      "    d = self.format_dict\n",
      "  File \"/home/bruce/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1476, in format_dict\n",
      "    'colour': self.colour}\n",
      "  File \"/home/bruce/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 204, in colour\n",
      "    return self.container.children[-2].style.bar_color\n",
      "AttributeError: 'FloatProgress' object has no attribute 'style'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x7f9e365a28c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bruce/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1162, in __del__\n",
      "    self.close()\n",
      "  File \"/home/bruce/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 288, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "  File \"/home/bruce/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 160, in display\n",
      "    d = self.format_dict\n",
      "  File \"/home/bruce/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1476, in format_dict\n",
      "    'colour': self.colour}\n",
      "  File \"/home/bruce/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 204, in colour\n",
      "    return self.container.children[-2].style.bar_color\n",
      "AttributeError: 'FloatProgress' object has no attribute 'style'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x7f9e365a28c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bruce/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1162, in __del__\n",
      "    self.close()\n",
      "  File \"/home/bruce/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 288, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "  File \"/home/bruce/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 160, in display\n",
      "    d = self.format_dict\n",
      "  File \"/home/bruce/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1476, in format_dict\n",
      "    'colour': self.colour}\n",
      "  File \"/home/bruce/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 204, in colour\n",
      "    return self.container.children[-2].style.bar_color\n",
      "AttributeError: 'FloatProgress' object has no attribute 'style'\n"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e0c634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 21\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5be6c7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "token_i = 5\n",
    "layer_i = 5\n",
    "vec = hidden_states[layer_i][batch_i][token_i]\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6738953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04f2147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/home/bruce/EP-M1/ML-DL/Project/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edd67454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>favorites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>verified</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>TweetID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt refarcir macron ans nom prépare</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3682</td>\n",
       "      <td>453535</td>\n",
       "      <td>3628</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1646978048000</td>\n",
       "      <td>832509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>populaire</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>1016</td>\n",
       "      <td>284</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1647694288000</td>\n",
       "      <td>1388011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>faut dégager cinglé</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1944</td>\n",
       "      <td>28234</td>\n",
       "      <td>1995</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1647370048000</td>\n",
       "      <td>63896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enseignants mettre prescriptions président rép...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1072</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/rytlted08g']</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1647256282000</td>\n",
       "      <td>979251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mafieuse oppressive macron</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13957</td>\n",
       "      <td>25311</td>\n",
       "      <td>10841</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1647258374000</td>\n",
       "      <td>1040049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>équipe campagne macron prie soutien sarko biza...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1081</td>\n",
       "      <td>83861</td>\n",
       "      <td>2631</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/jcafxdwm0w']</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1647454833000</td>\n",
       "      <td>98478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>envoies macron chameau cheval dessiné commission</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>499</td>\n",
       "      <td>3713</td>\n",
       "      <td>998</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/xhi5dwpvhb']</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1647436595000</td>\n",
       "      <td>20907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>emmanuel macron annule venue soirée électorale...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>86937</td>\n",
       "      <td>119219</td>\n",
       "      <td>750</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/pzjwqwm83o']</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>1647520208000</td>\n",
       "      <td>571044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>violer pauvre ukrainienne abusée africains düs...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>2397</td>\n",
       "      <td>178</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1647366716000</td>\n",
       "      <td>312667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>petites minutes temps temps bfm heures offre m...</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>239</td>\n",
       "      <td>46</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://t.co/knuch3htt9']</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1647164428000</td>\n",
       "      <td>789217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  retweets_count  \\\n",
       "0                 rt refarcir macron ans nom prépare               3   \n",
       "1                                          populaire               0   \n",
       "2                                faut dégager cinglé               3   \n",
       "3  enseignants mettre prescriptions président rép...               0   \n",
       "4                         mafieuse oppressive macron               0   \n",
       "5  équipe campagne macron prie soutien sarko biza...               2   \n",
       "6   envoies macron chameau cheval dessiné commission               3   \n",
       "7  emmanuel macron annule venue soirée électorale...               1   \n",
       "8  violer pauvre ukrainienne abusée africains düs...               0   \n",
       "9  petites minutes temps temps bfm heures offre m...               2   \n",
       "\n",
       "   favorites_count  followers_count  statuses_count  friends_count mentions  \\\n",
       "0                0             3682          453535           3628       []   \n",
       "1                0               86            1016            284       []   \n",
       "2                1             1944           28234           1995       []   \n",
       "3                0                1            1072              0       []   \n",
       "4                0            13957           25311          10841       []   \n",
       "5                0             1081           83861           2631       []   \n",
       "6                0              499            3713            998       []   \n",
       "7                0            86937          119219            750       []   \n",
       "8                0               95            2397            178       []   \n",
       "9               14                2             239             46       []   \n",
       "\n",
       "                          urls  verified hashtags      timestamp  TweetID  \n",
       "0                           []         0       []  1646978048000   832509  \n",
       "1                           []         0       []  1647694288000  1388011  \n",
       "2                           []         0       []  1647370048000    63896  \n",
       "3  ['https://t.co/rytlted08g']         0       []  1647256282000   979251  \n",
       "4                           []         0       []  1647258374000  1040049  \n",
       "5  ['https://t.co/jcafxdwm0w']         0       []  1647454833000    98478  \n",
       "6  ['https://t.co/xhi5dwpvhb']         0       []  1647436595000    20907  \n",
       "7  ['https://t.co/pzjwqwm83o']         1       []  1647520208000   571044  \n",
       "8                           []         0       []  1647366716000   312667  \n",
       "9  ['https://t.co/knuch3htt9']         0       []  1647164428000   789217  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c3b4b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vote définition secret con cons brassens etonnant cacher date dernière coloscopie flou loup'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][20.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f5d744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
